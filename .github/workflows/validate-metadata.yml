# GitHub Actions Workflow for curatedMetagenomicDataCuration
# 
# INSTALLATION INSTRUCTIONS:
# 1. Copy this file to: .github/workflows/validate-metadata.yml
#    in the waldronlab/curatedMetagenomicDataCuration repository
# 
# 2. Create a Personal Access Token (PAT) in OmicsMLRepoCuration repo:
#    - Go to Settings > Secrets and variables > Actions
#    - Create new secret: DEPENDENT_REPO_TOKEN
#    - Give it 'repo' scope to trigger workflows in other repos
# 
# 3. Enable workflow permissions:
#    - Go to Settings > Actions > General
#    - Under "Workflow permissions", select "Read and write permissions"
# 
# 4. Configure branch protection (optional but recommended):
#    - Go to Settings > Branches
#    - Add rule for 'master' branch
#    - Enable "Require status checks to pass before merging"
#    - Select "validate" as required check

name: Validate Metadata Against Latest Schema

on:
  # Validate on every push to main branches
  push:
    branches:
      - master
      - main
    paths:
      - 'inst/harmonized/**/*.tsv'
      - 'docs/**'
      - '.github/workflows/validate-metadata.yml'
  
  # Validate on pull requests
  pull_request:
    paths:
      - 'inst/harmonized/**/*.tsv'
  
  # Run daily at 2 AM UTC to catch upstream schema changes
  schedule:
    - cron: '0 2 * * *'
  
  # Allow manual trigger from Actions tab
  workflow_dispatch:
  
  # Triggered by OmicsMLRepoCuration when schema updates
  repository_dispatch:
    types: [schema-updated]

jobs:
  validate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout metadata repository
        uses: actions/checkout@v3
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: 'release'
          use-public-rspm: true  # KEY: Use binaries
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libxml2-dev libssl-dev libglpk-dev
      
      - name: Cache R packages
        uses: actions/cache@v3
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-${{ hashFiles('DESCRIPTION') }}
          restore-keys: ${{ runner.os }}-r-
      
      - name: Install OmicsMLRepoCuration (latest from GitHub)
        env:
          GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Install required system dependencies
          install.packages("remotes", repos = "https://cloud.r-project.org")
          
          # Install Bioconductor packages first
          if (!requireNamespace("BiocManager", quietly = TRUE))
              install.packages("BiocManager", repos = "https://cloud.r-project.org")
          
          BiocManager::install("rols", update = FALSE, ask = FALSE, force = TRUE)
          
          # Install OmicsMLRepoCuration with explicit error handling
          tryCatch({
            remotes::install_github(
              "shbrief/OmicsMLRepoCuration", 
              dependencies = TRUE,
              upgrade = "never",  # to avoid unnecessary recompilation
              force = TRUE,
              build_vignettes = FALSE,
              repos = BiocManager::repositories()
            )
            
            # Verify installation
            if (!require("OmicsMLRepoCuration", quietly = TRUE)) {
              stop("OmicsMLRepoCuration package failed to load after installation")
            }
            cat("‚úÖ OmicsMLRepoCuration installed successfully\n")
          }, error = function(e) {
            cat("‚ùå Installation failed:", conditionMessage(e), "\n")
            quit(status = 1)
          })
        shell: Rscript {0}
        
      - name: Get schema version info
        id: schema_info
        run: |
          SCHEMA_COMMIT=$(Rscript -e "cat(system('git ls-remote https://github.com/shbrief/OmicsMLRepoCuration HEAD | cut -f1', intern = TRUE))")
          SCHEMA_COMMIT_SHORT="${SCHEMA_COMMIT:0:7}"
          echo "commit=$SCHEMA_COMMIT" >> $GITHUB_OUTPUT
          echo "commit_short=$SCHEMA_COMMIT_SHORT" >> $GITHUB_OUTPUT
      
      - name: Find all metadata files
        id: find_files
        run: |
          FILES=$(find inst/harmonized -name "*_sample.tsv" -type f)
          COUNT=$(echo "$FILES" | wc -l)
          echo "count=$COUNT" >> $GITHUB_OUTPUT
          echo "Found $COUNT metadata files to validate"
          echo "$FILES"
      
      - name: Validate all metadata files
        id: validate
        run: |
          library(OmicsMLRepoCuration)
          library(jsonlite)
          
          # Load latest schema
          cat("Loading schema from OmicsMLRepoCuration...\n")
          schema_file <- system.file("schema", "cmd_data_dictionary.yaml", package = "OmicsMLRepoCuration")
          schema <- load_metadata_schema(schema_file)
          cat("‚úì Schema loaded successfully\n\n")
          
          # Find all *_sample.tsv files
          metadata_files <- list.files(
            path = "inst/harmonized/",
            pattern = "_sample\\.tsv$",
            full.names = TRUE,
            recursive = TRUE
          )
          
          cat("Found", length(metadata_files), "metadata files to validate\n\n")
          
          # Track validation results
          results <- list()
          all_valid <- TRUE
          total_errors <- 0
          total_warnings <- 0
          
          studies_with_issues <- list()
          studies_with_issues_json <- list()

          # Track harmonized metadata stats
          total_samples <- 0
          age_group_counts <- integer(0)
          body_site_counts <- integer(0)
          published_year_counts <- integer(0)
          country_counts <- integer(0)
          ancestry_counts <- integer(0)
          disease_counts <- integer(0)
          sex_counts <- integer(0)

          normalize_values <- function(x) {
            x <- as.character(x)
            x <- trimws(x)
            x <- x[!is.na(x) & nzchar(x)]
            x
          }

          split_values <- function(x) {
            x <- normalize_values(x)
            if (length(x) == 0) return(character(0))
            x <- unlist(strsplit(x, "\\s*[;|,]\\s*"))
            normalize_values(x)
          }

          update_counts <- function(counts, values) {
            vals <- split_values(values)
            if (length(vals) == 0) return(counts)
            tbl <- table(vals)
            for (n in names(tbl)) {
              counts[n] <- if (!is.na(counts[n])) counts[n] + tbl[[n]] else tbl[[n]]
            }
            counts
          }

          find_col <- function(cols, candidates) {
            idx <- which(tolower(cols) %in% tolower(candidates))
            if (length(idx) > 0) cols[idx[1]] else NA_character_
          }

          build_distribution <- function(counts, top_n = 10) {
            if (length(counts) == 0) {
              return(list(top = list(), total_distinct = 0, total_count = 0))
            }
            counts <- sort(counts, decreasing = TRUE)
            total_count <- sum(counts)
            total_distinct <- length(counts)
            top <- head(counts, top_n)
            top_list <- lapply(names(top), function(n) {
              list(name = n, count = as.integer(top[[n]]))
            })
            list(
              top = top_list,
              total_distinct = as.integer(total_distinct),
              total_count = as.integer(total_count)
            )
          }
          
          # Validate each file
          for (file in metadata_files) {
            study_name <- basename(dirname(file))
            
            tryCatch({
              # Read TSV file
              data <- read.delim(file, stringsAsFactors = FALSE, check.names = FALSE)

              # Update harmonized metadata stats
              total_samples <- total_samples + nrow(data)
              cols <- colnames(data)

              age_group_col <- find_col(cols, c("age_group", "agegroup"))
              if (!is.na(age_group_col)) {
                age_group_counts <- update_counts(age_group_counts, data[[age_group_col]])
              }

              body_site_col <- find_col(cols, c("body_site", "bodysite", "body_site_ontology"))
              if (!is.na(body_site_col)) {
                body_site_counts <- update_counts(body_site_counts, data[[body_site_col]])
              }

              # Extract published year from study directory name (Author_Year pattern)
              year_match <- regmatches(study_name, regexpr("\\d{4}$", study_name))
              if (length(year_match) == 1 && nzchar(year_match)) {
                yr <- year_match
                published_year_counts[yr] <- if (!is.na(published_year_counts[yr])) published_year_counts[yr] + as.integer(nrow(data)) else as.integer(nrow(data))
              }

              country_col <- find_col(cols, c("country", "host_country", "location", "geo_loc_name"))
              if (!is.na(country_col)) {
                country_counts <- update_counts(country_counts, data[[country_col]])
              }

              ancestry_col <- find_col(cols, c("ancestry", "ethnicity", "race"))
              if (!is.na(ancestry_col)) {
                ancestry_counts <- update_counts(ancestry_counts, data[[ancestry_col]])
              }

              disease_col <- find_col(cols, c("disease", "study_condition", "diagnosis", "disease_type"))
              if (!is.na(disease_col)) {
                disease_counts <- update_counts(disease_counts, data[[disease_col]])
              }

              sex_col <- find_col(cols, c("sex", "gender", "host_sex"))
              if (!is.na(sex_col)) {
                sex_counts <- update_counts(sex_counts, data[[sex_col]])
              }
              
              # Validate against schema
              result <- validate_data_against_schema(data, schema)
              
              # Store results
              results[[study_name]] <- result
              
              # Check if there are errors or warnings
              has_errors <- length(result$errors) > 0
              has_warnings <- length(result$warnings) > 0
              
              if (has_errors || has_warnings) {
                # Store study with issues for reporting
                studies_with_issues[[study_name]] <- list(
                  file = file,
                  rows = nrow(data),
                  cols = ncol(data),
                  errors = result$errors,
                  warnings = result$warnings
                )
                
                # Store for JSON output
                studies_with_issues_json[[length(studies_with_issues_json) + 1]] <- list(
                  name = study_name,
                  file = file,
                  rows = nrow(data),
                  cols = ncol(data),
                  errors = as.list(result$errors),
                  warnings = as.list(result$warnings)
                )
                
                if (has_errors) {
                  all_valid <- FALSE
                  total_errors <- total_errors + length(result$errors)
                }
                
                if (has_warnings) {
                  total_warnings <- total_warnings + length(result$warnings)
                }
              }
              
            }, error = function(e) {
              studies_with_issues[[study_name]] <- list(
                file = file,
                rows = NA,
                cols = NA,
                errors = paste("VALIDATION ERROR:", conditionMessage(e)),
                warnings = character(0)
              )
              
              studies_with_issues_json[[length(studies_with_issues_json) + 1]] <- list(
                name = study_name,
                file = file,
                rows = NA,
                cols = NA,
                errors = list(paste("VALIDATION ERROR:", conditionMessage(e))),
                warnings = list()
              )
              
              all_valid <- FALSE
              total_errors <- total_errors + 1
            })
          }
          
          # Report only studies with issues
          if (length(studies_with_issues) > 0) {
            cat("\n", rep("=", 70), "\n", sep = "")
            cat("STUDIES WITH ERRORS/WARNINGS (", length(studies_with_issues), " of ", length(metadata_files), ")\n", sep = "")
            cat(rep("=", 70), "\n", sep = "")
            
            for (study_name in names(studies_with_issues)) {
              study <- studies_with_issues[[study_name]]
              cat("\n", rep("-", 70), "\n", sep = "")
              cat("Study:", study_name, "\n")
              cat("File:", study$file, "\n")
              if (!is.na(study$rows)) {
                cat("Rows:", study$rows, " | Columns:", study$cols, "\n")
              }
              cat(rep("-", 70), "\n", sep = "")
              
              # Report errors
              if (length(study$errors) > 0) {
                cat("‚ùå ERRORS (", length(study$errors), "):\n", sep = "")
                for (i in seq_along(study$errors)) {
                  cat("  ", i, ". ", study$errors[i], "\n", sep = "")
                }
              }
              
              # Report warnings
              if (length(study$warnings) > 0) {
                cat("‚ö†Ô∏è  WARNINGS (", length(study$warnings), "):\n", sep = "")
                for (i in seq_along(study$warnings)) {
                  cat("  ", i, ". ", study$warnings[i], "\n", sep = "")
                }
              }
            }
          } else {
            cat("\n‚úÖ All studies passed validation without errors or warnings!\n")
          }
          
          # Summary
          cat("\n", rep("=", 70), "\n", sep = "")
          cat("VALIDATION SUMMARY\n")
          cat(rep("=", 70), "\n", sep = "")
          cat("Total files validated:", length(metadata_files), "\n")
          cat("Total errors:", total_errors, "\n")
          cat("Total warnings:", total_warnings, "\n")
          cat("Status:", if(all_valid) "‚úÖ PASS" else "‚ùå FAIL", "\n")
          cat(rep("=", 70), "\n\n", sep = "")
          
          # Save summary for GitHub Actions (via environment file)
          gh_output <- Sys.getenv("GITHUB_OUTPUT")
          if (nzchar(gh_output)) {
            cat("total_files=", length(metadata_files), "\n", sep = "", file = gh_output, append = TRUE)
            cat("total_errors=", total_errors, "\n", sep = "", file = gh_output, append = TRUE)
            cat("total_warnings=", total_warnings, "\n", sep = "", file = gh_output, append = TRUE)
            cat("files_with_issues=", length(studies_with_issues), "\n", sep = "", file = gh_output, append = TRUE)
          }

          # Generate Markdown summary for GITHUB_STEP_SUMMARY
          summary_lines <- c(
            "# \U0001F52C Metadata Validation Summary",
            "",
            paste0("**Status:** ", if(all_valid) "\u2705 PASS" else "\u274C FAIL"),
            paste0("**Date:** ", format(Sys.time(), "%Y-%m-%d %H:%M:%S UTC", tz = "UTC")),
            "",
            "## Validation Results",
            "",
            "| Metric | Value |",
            "|--------|------:|",
            paste0("| Files validated | ", length(metadata_files), " |"),
            paste0("| Files with issues | ", length(studies_with_issues), " |"),
            paste0("| Total errors | ", total_errors, " |"),
            paste0("| Total warnings | ", total_warnings, " |"),
            "",
            "## Harmonized Metadata Statistics",
            "",
            "| Metric | Value |",
            "|--------|------:|",
            paste0("| Total studies | ", length(metadata_files), " |"),
            paste0("| Total samples | ", total_samples, " |"),
            paste0("| Distinct countries | ", length(country_counts), " |"),
            paste0("| Distinct diseases | ", length(disease_counts), " |"),
            paste0("| Distinct body sites | ", length(body_site_counts), " |"),
            ""
          )

          # Top distributions helper
          format_top <- function(counts, title, n = 5) {
            if (length(counts) == 0) return(character(0))
            counts <- sort(counts, decreasing = TRUE)
            top <- head(counts, n)
            c(
              paste0("### ", title, " (top ", min(n, length(top)), ")"),
              "",
              "| Name | Count |",
              "|------|------:|",
              vapply(names(top), function(nm) {
                paste0("| ", nm, " | ", top[[nm]], " |")
              }, character(1)),
              ""
            )
          }

          summary_lines <- c(summary_lines,
            format_top(body_site_counts, "\U0001F9EC Body Site"),
            format_top(disease_counts, "\U0001F3E5 Disease"),
            format_top(country_counts, "\U0001F30D Country"),
            format_top(sex_counts, "\U0001F464 Sex"),
            format_top(age_group_counts, "\U0001F4C5 Age Group")
          )

          # Studies with issues details (collapsible)
          if (length(studies_with_issues) > 0) {
            summary_lines <- c(summary_lines,
              "## Studies with Issues",
              "",
              "<details>",
              paste0("<summary>\u26A0\uFE0F ", length(studies_with_issues), " studies have errors or warnings (click to expand)</summary>"),
              ""
            )
            for (study_name in names(studies_with_issues)) {
              study <- studies_with_issues[[study_name]]
              summary_lines <- c(summary_lines,
                paste0("#### ", study_name)
              )
              if (length(study$errors) > 0) {
                for (err in study$errors) {
                  summary_lines <- c(summary_lines, paste0("- \u274C ", err))
                }
              }
              if (length(study$warnings) > 0) {
                for (wrn in study$warnings) {
                  summary_lines <- c(summary_lines, paste0("- \u26A0\uFE0F ", wrn))
                }
              }
              summary_lines <- c(summary_lines, "")
            }
            summary_lines <- c(summary_lines, "</details>", "")
          }

          writeLines(summary_lines, "validation_summary.md")
          
          # Generate JSON report for GitHub Pages
          json_report <- list(
            status = if(all_valid) "PASS" else "FAIL",
            summary = list(
              total_files = length(metadata_files),
              total_errors = total_errors,
              total_warnings = total_warnings,
              files_with_issues = length(studies_with_issues)
            ),
            stats = list(
              total_studies = length(metadata_files),
              total_samples = as.integer(total_samples),
              distributions = list(
                age_group = build_distribution(age_group_counts),
                body_site = build_distribution(body_site_counts),
                published_year = build_distribution(published_year_counts),
                country = build_distribution(country_counts),
                ancestry = build_distribution(ancestry_counts),
                disease = build_distribution(disease_counts),
                sex = build_distribution(sex_counts)
              )
            ),
            metadata = list(
              timestamp = format(Sys.time(), "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"),
              trigger = "${{ github.event_name }}",
              branch = "${{ github.ref_name }}",
              schema_commit = "${{ steps.schema_info.outputs.commit }}",
              schema_commit_short = "${{ steps.schema_info.outputs.commit_short }}",
              run_id = "${{ github.run_id }}"
            ),
            studies_with_issues = studies_with_issues_json
          )
          
          # Write JSON to file
          writeLines(toJSON(json_report, auto_unbox = TRUE, pretty = TRUE), "docs/validation_results.json")
          cat("\n‚úÖ JSON report generated: docs/validation_results.json\n")
          
          # Fail workflow if validation failed
          if (!all_valid) {
            cat("\nüö® VALIDATION FAILED!\n\n")
            cat("Please update your metadata to match the latest schema from:\n")
            cat("https://github.com/shbrief/OmicsMLRepoCuration\n\n")
            cat("Schema commit: ${{ steps.schema_info.outputs.commit_short }}\n\n")
            stop("Metadata validation failed! See errors above.")
          }
          
          cat("\n‚úÖ All metadata files are valid against the latest schema!\n")
        shell: Rscript {0}
        continue-on-error: false
      
      - name: Generate validation badge
        if: always()
        run: |
          if [ "${{ steps.validate.outcome }}" == "success" ]; then
            echo "![Validation Status](https://img.shields.io/badge/validation-passing-brightgreen)" > validation_badge.md
          else
            echo "![Validation Status](https://img.shields.io/badge/validation-failing-red)" > validation_badge.md
          fi
      
      - name: Create validation report and job summary
        if: always()
        run: |
          cat << 'REPORT' > validation_report.md
          # Metadata Validation Report
          
          **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Trigger:** ${{ github.event_name }}
          **Branch:** ${{ github.ref_name }}
          
          ## Schema Information
          - **Repository:** shbrief/OmicsMLRepoCuration
          - **Commit:** ${{ steps.schema_info.outputs.commit_short }}
          
          ## Results
          - **Total Files:** ${{ steps.find_files.outputs.count }}
          - **Status:** ${{ steps.validate.outcome == 'success' && '‚úÖ PASS' || '‚ùå FAIL' }}
          
          REPORT
          
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            cat << 'REPORT' >> validation_report.md
          ## Schema Update Details
          - **Triggered by:** Schema update in OmicsMLRepoCuration
          - **Schema Commit:** ${{ github.event.client_payload.schema_commit_short }}
          - **Changed Files:** ${{ github.event.client_payload.changed_files }}
          
          REPORT
          fi
          
          cat validation_report.md
          
          # Write the rich summary to the GitHub Actions Summary tab
          if [ -f validation_summary.md ]; then
            cat validation_summary.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "## ‚ö†Ô∏è Validation summary was not generated" >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "The R validation step may have failed before producing a summary." >> "$GITHUB_STEP_SUMMARY"
          fi
          
          # Append schema & trigger metadata to the summary tab
          {
            echo ""
            echo "---"
            echo "**Schema:** [OmicsMLRepoCuration @ ${{ steps.schema_info.outputs.commit_short }}](https://github.com/shbrief/OmicsMLRepoCuration/commit/${{ steps.schema_info.outputs.commit }})"
            echo "**Trigger:** \`${{ github.event_name }}\` on branch \`${{ github.ref_name }}\`"
          } >> "$GITHUB_STEP_SUMMARY"
      
      - name: Upload validation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation_report.md
      
      - name: Deploy to GitHub Pages
        if: always() && github.ref == 'refs/heads/master'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
          publish_branch: gh-pages
          commit_message: 'Update validation results'
      
      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('validation_report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
      
      - name: Notification on failure
        if: failure() && github.event_name == 'repository_dispatch'
        run: |
          echo "üö® Validation failed after schema update!"
          echo "Schema was updated in OmicsMLRepoCuration commit ${{ github.event.client_payload.schema_commit_short }}"
          echo "Action required: Update metadata files to match new schema"
